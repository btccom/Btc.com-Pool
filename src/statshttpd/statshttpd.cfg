#
# stats server cfg
#
# @since 2016-07
# @copyright btc.com
#

kafka = {
  brokers = "127.0.0.1:9092"; # "10.0.0.1:9092,10.0.0.2:9092,..."
};

statshttpd = {
  ip = "0.0.0.0";
  port = 8080;

  # interval seconds, flush workers data into database
  # it's very fast because we use insert statement with multiple values and
  # merge table when flush data to DB. we have test mysql, it could flush
  # 25,000 workers into DB in about 1.7 seconds.
  flush_db_interval = 15;
  # write last db flush time to file
  file_last_flush_time = "/work/btcpool/build/run_statshttpd/statshttpd_lastflushtime.txt";

  # write mining workers' info to mysql database
  use_mysql = true;
  # write mining workers' info to redis
  use_redis = false;
};


#
# pool mysql db, table: mining_workers
#
pooldb = {
  host = "127.0.0.1";
  port = 3306;
  username = "root";
  password = "root";
  dbname = "bpool_local_db";
};

#
# pool redis
#
redis = {
  host = "127.0.0.1";
  port = 6379;
  password = ""; # keep it empty if no password auth required

  # keys:
  #     worker: HGETALL    "{key_prefix}mining_workers/pu/{puid}/wk/{workerid}"
  #             PSUBSCRIBE "{key_prefix}mining_workers/pu/{puid}/wk/*"
  #     user:   HGETALL    "{key_prefix}mining_workers/pu/{puid}/all"
  #             PSUBSCRIBE "{key_prefix}mining_workers/pu/*/all"
  key_prefix = "";
  # expiration seconds of every key:
  key_expire = 900;
};
